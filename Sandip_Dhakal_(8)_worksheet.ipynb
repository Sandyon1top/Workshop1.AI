{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOta/G0YpAE4+Qh4HQXTunZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sandyon1top/Workshop1.AI/blob/main/Sandip_Dhakal_(8)_worksheet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qODsNitewEmS",
        "outputId": "e57aec47-88b6-499b-8c9d-4bfa29ab5a5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the Wine Dataset from scikit-learn\n",
        "1. Implement Classification Models:\n",
        "• Train a Decision Tree Classifier and a Random Forest Classifier using scikit-learn.\n",
        "• Compare the models based on their F1 scores."
      ],
      "metadata": {
        "id": "tVKe8WnLA3Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import RandomizedSearchCV ,GridSearchCV,train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor ,RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error ,accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.tree import DecisionTreeRegressor , DecisionTreeClassifier\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "#the Wine dataset\n",
        "data = load_wine()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Decision Tree Classifier\n",
        "decision_tree = DecisionTreeClassifier(random_state=42)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "y_pred_tree = decision_tree.predict(X_test)\n",
        "f1_tree = f1_score(y_test, y_pred_tree, average=\"weighted\")\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "random_forest = RandomForestClassifier(random_state=42)\n",
        "random_forest.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest.predict(X_test)\n",
        "f1_rf = f1_score(y_test, y_pred_rf, average=\"weighted\")\n",
        "\n",
        "# --- Compare F1 Scores ---\n",
        "print(\"Decision Tree F1 Score:\", f1_tree)\n",
        "print(\"Random Forest F1 Score:\", f1_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvo-BivI7GCR",
        "outputId": "e894cf52-0ad0-4f1c-be19-172e7ca5a793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree F1 Score: 0.9439974457215836\n",
            "Random Forest F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter Tuning:\n",
        "• Identify three hyperparameters of the Random Forest Classifier.\n",
        "• Perform hyperparameter tuning using GridSearchCV to optimize these parameters.\n",
        "• Take hints from the scikit-learn documentation to guide the implementation."
      ],
      "metadata": {
        "id": "xtbOKksRA8bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define Random Forest Classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define Hyperparameter Grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],          # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],        # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10]         # Minimum number of samples required to split an internal node\n",
        "}\n",
        "\n",
        "# Performing GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_best)\n",
        "print(\"Accuracy with Best Parameters:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzqOiyD7vXz",
        "outputId": "8879d696-a9eb-4df0-d031-697ee0e829c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n",
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "Accuracy with Best Parameters: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Implement Regression Model:\n",
        "• Train a Decision Tree Regressor and a Random Forest Regressor using scikit-learn.\n",
        "• Identify three parameters for Random Forest Regressio and Perform hyperparameter tuning using\n",
        "RandomSearchCV to optimize these parameters."
      ],
      "metadata": {
        "id": "mS-Dz41TBCCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Decision Tree Regressor\n",
        "decision_tree_reg = DecisionTreeRegressor(random_state=42)\n",
        "decision_tree_reg.fit(X_train, y_train)\n",
        "y_pred_tree = decision_tree_reg.predict(X_test)\n",
        "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
        "print(\"Decision Tree Regressor MSE:\", mse_tree)\n",
        "\n",
        "#Train Random Forest Regressor\n",
        "random_forest_reg = RandomForestRegressor(random_state=42)\n",
        "random_forest_reg.fit(X_train, y_train)\n",
        "y_pred_rf = random_forest_reg.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "print(\"Random Forest Regressor MSE:\", mse_rf)\n",
        "\n",
        "# Performing Hyperparameter Tuning for Random Forest Regressor\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 200, 300],          # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 20, 30],             # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 10],             # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4]                # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=random_forest_reg, param_distributions=param_dist,\n",
        "                                   n_iter=10, cv=3, scoring='neg_mean_squared_error', random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# --- Print Best Parameters and MSE ---\n",
        "print(\"Best Parameters (Random Forest Regressor):\", random_search.best_params_)\n",
        "best_rf_model = random_search.best_estimator_\n",
        "y_pred_best_rf = best_rf_model.predict(X_test)\n",
        "mse_best_rf = mean_squared_error(y_test, y_pred_best_rf)\n",
        "print(\"Random Forest Regressor MSE with Best Parameters:\", mse_best_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bosp1hfm9RmG",
        "outputId": "151a4aff-1809-4ed6-ef7b-40cab5a14ee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Regressor MSE: 0.16666666666666666\n",
            "Random Forest Regressor MSE: 0.06483333333333333\n",
            "Best Parameters (Random Forest Regressor): {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 20}\n",
            "Random Forest Regressor MSE with Best Parameters: 0.06225286644132144\n"
          ]
        }
      ]
    }
  ]
}