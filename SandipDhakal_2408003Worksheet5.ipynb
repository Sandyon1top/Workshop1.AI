{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3WTIq63erqF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45-Ew-4Ee1GP"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bm_a_Ypye5Bo",
        "outputId": "b3b4496e-a724-4197-8341-9d586f54f4da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Proceed Further\n",
            "Cost function output:  0.0\n"
          ]
        }
      ],
      "source": [
        "#Sandip Dhakal\n",
        "#1\n",
        "import numpy as np\n",
        "\n",
        "def cost_function(x, y, w):\n",
        "  \"\"\"\n",
        "  Parameters:\n",
        "  This function finds the Mean Square Error.\n",
        "  Input parameters:\n",
        "  X: Feature Matrix\n",
        "  Y: Target Matrix\n",
        "  W: Weight Matrix\n",
        "  Output Parameters:\n",
        "  cost: accumulated mean square error.\n",
        "  \"\"\"\n",
        "  n = len(y)\n",
        "  y_pred = np.dot(x, w)\n",
        "  squared_errors = np.square(y_pred - y)\n",
        "  cost = (1 / (2 * n)) * np.sum(squared_errors)\n",
        "  return cost\n",
        "\n",
        "# Test case\n",
        "x_test = np.array([[1,2], [3,4], [5,6]])\n",
        "y_test = np.array([3,7,11])\n",
        "w_test = np.array([1,1])\n",
        "cost = cost_function(x_test, y_test, w_test)\n",
        "if cost == 0:\n",
        "  print(\"Proceed Further\")\n",
        "else:\n",
        "  print(\"Something went wrong: Reimplement a cost function\")\n",
        "print(\"Cost function output: \", cost_function(x_test, y_test, w_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqDcu3ZYfFcs",
        "outputId": "e8cf1bd5-6f61-4434-9481-3c6f71d8255f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Parameters: [0.20551667 0.54295081 0.10388027]\n",
            "Cost History (first 10 values): [0.10711197094660153, 0.10634880599939901, 0.10559826315680618, 0.10486012948320558, 0.1041341956428534, 0.10342025583900626, 0.1027181077540776, 0.1020275524908062, 0.10134839451441931, 0.1006804415957737]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cost_function(X, Y, W):\n",
        "    \"\"\"\n",
        "    Parameters:\n",
        "    X: Feature Matrix\n",
        "    Y: Target Matrix\n",
        "    W: Weight Matrix\n",
        "\n",
        "    Returns:\n",
        "    cost: Accumulated mean square error.\n",
        "    \"\"\"\n",
        "    m = len(Y)\n",
        "    Y_pred = np.dot(X, W)\n",
        "    squared_errors = np.square(Y_pred - Y)\n",
        "    cost = (1 / (2 * m)) * np.sum(squared_errors)\n",
        "    return cost\n",
        "\n",
        "def gradient_descent(X, Y, W, alpha, iterations):\n",
        "    \"\"\"\n",
        "    Perform gradient descent to optimize the parameters of a linear regression model.\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Feature matrix (m x n).\n",
        "    Y (numpy.ndarray): Target vector (m x 1).\n",
        "    W (numpy.ndarray): Initial guess for parameters (n x 1).\n",
        "    alpha (float): Learning rate.\n",
        "    iterations (int): Number of iterations for gradient descent.\n",
        "\n",
        "    Returns:\n",
        "    tuple: A tuple containing the final optimized parameters (W_update) and the history of cost values.\n",
        "    W_update (numpy.ndarray): Updated parameters (n x 1).\n",
        "    cost_history (list): History of cost values over iterations.\n",
        "    \"\"\"\n",
        "    cost_history = [0] * iterations\n",
        "    m = len(Y)\n",
        "    for iteration in range(iterations):\n",
        "        Y_pred = np.dot(X, W)\n",
        "        loss = Y_pred - Y\n",
        "        dw = (1 / m) * np.dot(X.T, loss)\n",
        "        W_update = W - alpha * dw\n",
        "        cost = cost_function(X, Y, W_update)\n",
        "        cost_history[iteration] = cost\n",
        "        W = W_update\n",
        "    return W_update, cost_history\n",
        "\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 3)\n",
        "Y = np.random.rand(100)\n",
        "W = np.random.rand(3)\n",
        "\n",
        "alpha = 0.01\n",
        "iterations = 1000\n",
        "\n",
        "final_params, cost_history = gradient_descent(X, Y, W, alpha, iterations)\n",
        "\n",
        "print(\"Final Parameters:\", final_params)\n",
        "print(\"Cost History (first 10 values):\", cost_history[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M30VECzdf4bB",
        "outputId": "acd47f80-ebbe-4efa-b4e6-5d3c04f6f7d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RMSE:  0.431377337944294\n",
            "R2:  -1.1215707120566534\n"
          ]
        }
      ],
      "source": [
        "#3\n",
        "# Model Evaluation - RMSE\n",
        "def rmse(y, y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the Root Mean Squres.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rmse: Root Mean Square.\n",
        "  \"\"\"\n",
        "\n",
        "  squared_diff = (y - y_pred) ** 2\n",
        "\n",
        "  mse = np.mean(squared_diff)\n",
        "\n",
        "  rmse = np.sqrt(mse)\n",
        "  return rmse\n",
        "\n",
        "def r2(y, y_pred):\n",
        "  \"\"\"\n",
        "  This Function calculates the R Squared Error.\n",
        "  Input Arguments:\n",
        "  Y: Array of actual(Target) Dependent Varaibles.\n",
        "  Y_pred: Array of predeicted Dependent Varaibles.\n",
        "  Output Arguments:\n",
        "  rsquared: R Squared Error.\n",
        "  \"\"\"\n",
        "  mean_y = np.mean(y)\n",
        "  ss_tot = np.sum((y - mean_y) ** 2)\n",
        "  ss_res = np.sum((y - y_pred) ** 2)\n",
        "  r2 = 1 - (ss_res / ss_tot)\n",
        "  return r2\n",
        "\n",
        "\n",
        "y = np.random.rand(100)\n",
        "y_pred = np.random.rand(100)\n",
        "\n",
        "\n",
        "rmse_value = rmse(y, y_pred)\n",
        "print(\"RMSE: \", rmse_value)\n",
        "\n",
        "\n",
        "r2_value = r2(y, y_pred)\n",
        "print(\"R2: \", r2_value)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
